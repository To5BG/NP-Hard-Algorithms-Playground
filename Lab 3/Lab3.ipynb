{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from functools import reduce\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bernoulli generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli(s, p, low=0, high=1):\n",
    "    samples = np.random.choice([low, high], size=s, p=[1-p, p])\n",
    "    flattened = samples.flatten()\n",
    "    return samples, np.unique(flattened, return_counts=True)[1] / len(flattened)\n",
    "\n",
    "n, p = 1_000_000, 0.5\n",
    "samples, probs = bernoulli(n, p)\n",
    "bar = plt.bar(np.array([0, 1]), probs)\n",
    "plt.bar_label(bar, np.bincount(samples.flatten(), minlength=2))\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Discrete probability (P(x = k))\")\n",
    "plt.title(\"Bernoulli distribution, %s samples and p = %.2f\" % (n, p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_empiric(s, n, p):\n",
    "    res = []\n",
    "    for _ in range(s):\n",
    "        res.append(np.where(bernoulli(n, p)[0] == 1)[0].shape[0])\n",
    "    return res, np.bincount(np.array(res), minlength=n + 1) / s\n",
    "\n",
    "s, n, p = 100_000, 10, 0.75\n",
    "plt.figure(figsize=[12, 5])\n",
    "samples, probs = binomial_empiric(s, n, p)\n",
    "bar = plt.bar(np.arange(n + 1), probs)\n",
    "plt.bar_label(bar, np.bincount(samples, minlength=n + 1))\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Discrete probability (P(x = k))\")\n",
    "plt.title(\"Binomial distribution, %d samples with n = %d and p = %.2f\" % (s, n, p))\n",
    "plt.show()\n",
    "\n",
    "def binomial_analytic(s, n, p):\n",
    "    probs = comb(n) * ((p ** np.arange(0, n + 1)) * ((1 - p) ** np.arange(n, -1, -1)))\n",
    "    return np.random.choice(np.arange(n + 1), size=s, p=probs), probs\n",
    "\n",
    "def comb(n):\n",
    "  res = []\n",
    "  for k in range(n + 1):\n",
    "    res.append(reduce(lambda x, i: x * (n - i) // (i + 1), range(min(k, n - k)), 1))\n",
    "  return res\n",
    "  \n",
    "plt.figure(figsize=[12, 5])\n",
    "samples, probs = binomial_analytic(s, n, p)\n",
    "bar = plt.bar(np.arange(n + 1), probs)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Discrete probability (P(x = k))\")\n",
    "plt.bar_label(bar, np.bincount(samples, minlength=n + 1))\n",
    "plt.title(\"Binomial distribution, %d samples with n = %d and p = %.2f\" % (s, n, p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_binomial_empiric(s, r, p):\n",
    "    res = []\n",
    "    for _ in range(s):\n",
    "      t, c = 0, 0\n",
    "      while True:\n",
    "        if bernoulli(1, p)[0] == 1: c += 1\n",
    "        else: t += 1\n",
    "        if c == r: break\n",
    "      res.append(t)\n",
    "    maxt = np.max(res)\n",
    "    return res, np.bincount(np.array(res)) / s, maxt\n",
    "\n",
    "s, r, p = 10000, 3, 0.5\n",
    "plt.figure(figsize=[12, 5])\n",
    "samples, probs, maxt = negative_binomial_empiric(s, r, p)\n",
    "bar = plt.bar(np.arange(maxt + 1), probs)\n",
    "plt.bar_label(bar, np.bincount(samples))\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Discrete probability (P(x = k))\")\n",
    "plt.title(\"Negative binomial distribution, %d samples with r = %d and p = %.2f\" % (s, r, p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p, s, t = 10, 0.7, 5_000, 6\n",
    "xs = np.array(binomial_empiric(s, n, p)[0])\n",
    "xs[np.where(xs != t)] = 0\n",
    "ys = np.cumsum(xs / t) / np.arange(1, len(xs) + 1)\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.title(\"Plot of P(X = %d), where X ~ Bn(%d, %.2f), estimated empirically over %d samples\" % (t, n, p, s))\n",
    "plt.ylabel(\"P(x = %d)\" % t)\n",
    "plt.xlabel(\"samples\")\n",
    "plt.plot(np.arange(1, len(xs) + 1), ys, label='Observed value')\n",
    "plt.plot(np.arange(1, len(xs) + 1), [sp.special.binom(n, t) * (p ** t) * ((1 - p) ** (n - t))] * len(xs), 'r', label='Theoretical expected value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p, s = 10, 0.7, 5000\n",
    "probs = binomial_analytic(s, n, p)[1]\n",
    "xs = np.array(binomial_empiric(s, n, p)[0])\n",
    "cums = []\n",
    "# I know I am ignoring k=0, but for ease of implementation I am skipping over it, and it is 'good enough' on the graphs\n",
    "for i in range(1, n + 1):\n",
    "    xss = np.copy(xs)\n",
    "    xss[np.where(xss != i)] = 0\n",
    "    cums.append(np.cumsum(xss / i) / np.arange(1, len(xss) + 1))\n",
    "\n",
    "ys = np.sum((np.array(cums) - np.tile(probs[1:], (len(xs), 1)).T) ** 2 / len(probs), axis=0)\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.title(\"Plot of MSE over all probabilities of X ~ Bn(%d, %.2f), estimated empirically over %d samples\" % (n, p, s))\n",
    "plt.ylabel(\"MSE over all probabilities\")\n",
    "plt.xlabel(\"samples\")\n",
    "plt.ylim([0, 0.01])\n",
    "plt.plot(np.arange(1, len(xs) + 1), ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(t, N):\n",
    "  res = bernoulli(np.ceil(t * N).astype(np.int32), 1/2, -1, 1)[0]\n",
    "  return np.sum(res) / np.sqrt(N)\n",
    "\n",
    "N = 10000\n",
    "plt.figure(figsize=[12, 5])\n",
    "v = []\n",
    "for t in np.linspace(0, 1, N): v.append(X(t, N))\n",
    "plt.stem(np.linspace(0, 1, N), v, markerfmt=\" \")\n",
    "plt.xlabel(\"t = n/N\")\n",
    "plt.ylabel(\"E[X(n/N)]\")\n",
    "plt.title(\"Trajectory of process X(n/N) = S_n / sqrt(N), with N = %d and p = 0.5\" % N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "res = bernoulli(N, 1/2, -1, 1)[0]\n",
    "Sn = np.cumsum(res) / np.sqrt(N)\n",
    "\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.plot(np.linspace(0, 1, N), Sn)\n",
    "plt.xlabel(\"t = n/N\")\n",
    "plt.ylabel(\"E[X(n/N)]\")\n",
    "plt.title(\"Trajectory of process X(n/N) = S_n / sqrt(N), with N = %d and p = 0.5\" % N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Symmetry property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cantor_empiric(s, low, high, terms=20):\n",
    "    xs = 2 * bernoulli((s, terms), 1/2, low, high)[0]\n",
    "    xs = np.sort(np.sum(xs * ((1/3) ** np.arange(1, terms + 1)), axis=1))\n",
    "    return xs, np.arange(1, len(xs) + 1) / len(xs)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.title(\"Cumulative distribution of Cantor distribution with different samples\")\n",
    "for d, c in zip([10, 100, 1000, 10_000, 100_000, 1_000_000], ['g', 'r', 'purple', 'b', 'y']):\n",
    "    x, y = cantor_empiric(d, 0, 1)\n",
    "    plt.step(x, y, c, label='%d' % d)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(cantor_empiric(100_000, 0, 1)[0], bins=100)\n",
    "plt.title('Cantor singular distribution, 100000 samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 10_000\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "(ax1, ax2), (ax3, ax4) = fig.subplots(2, 2)\n",
    "fig.suptitle(\"Cumulative distributions of Cantor random variable, shown over %d samples\" % s)\n",
    "\n",
    "# Regular cantor\n",
    "x1, y1 = cantor_empiric(s, 0, 1)\n",
    "# Flipped over 1/2\n",
    "x2, y2 = cantor_empiric(s, 0, 1)\n",
    "x2 = 1 - x2\n",
    "y2 = 1 - y2\n",
    "# Only 1/3 \n",
    "x3, y3 = cantor_empiric(s, 0, 1/3)\n",
    "# Scale down by 3\n",
    "x4, y4 = cantor_empiric(s, 0, 1)\n",
    "x4 /= 3\n",
    "\n",
    "for ax, x, y, title in zip([ax1, ax2, ax3, ax4], [x1, x2, x3, x4], [y1, y2, y3, y4], \\\n",
    "    [\"Regular cantor distribution (Z[0, 1])\", \"Inverted cantor distribution (1 - Z[0, 1])\", \"The first third of cantor distr (Z[0, 1/3])\", \"Scaled down cantor distr (Z[0, 1]/3)\"]):\n",
    "    ax.step(x, y)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Cumulative probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. From one distribution to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_empiric(s, lambd):\n",
    "    return -np.log(np.random.uniform(0, 1, s))/lambd\n",
    "        \n",
    "s, l, bins = 10_000_000, 0.45, 10000\n",
    "xrange = np.linspace(0, int(10 * l), bins)\n",
    "samples = np.bincount(np.digitize(exponential_empiric(s, l), xrange), minlength=bins)[:bins]\n",
    "plt.figure(figsize=[12, 5])\n",
    "# Max at x = 0\n",
    "plt.stem(xrange, samples * l / samples[np.argsort(samples)[-1]], markerfmt=\" \")\n",
    "# Closed form of exponential => λe^(-xλ)\n",
    "plt.plot(xrange, l * np.exp(- l * xrange), 'r')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Value of pdf (f(x))\")\n",
    "plt.title(\"Exponential distribution, %d samples and λ = %.2f\" % (s, l))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_empiric(s, lambd):\n",
    "    res = []\n",
    "    for _ in range(s):\n",
    "        c, t = -1, 0\n",
    "        while True:\n",
    "            c += 1\n",
    "            # t += exponential_empiric(1, 1/lambd)\n",
    "            # if t >= lambd ** 2: break\n",
    "            t += exponential_empiric(1, lambd)\n",
    "            if t >= 1: break\n",
    "        res.append(c)\n",
    "    return res, np.bincount(np.array(res)) / s, np.max(res)\n",
    "\n",
    "s, l = 100_000, 2.25\n",
    "samples, probs, maxt = poisson_empiric(s, l)\n",
    "plt.figure(figsize=[12, 5])\n",
    "bar = plt.bar(np.arange(maxt + 1), probs)\n",
    "plt.bar_label(bar, np.bincount(samples))\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Discrete probability (P(x = k))\")\n",
    "plt.title(\"Poisson distribution, %d samples with λ = %.2f\" % (s, l))\n",
    "plt.show()\n",
    "\n",
    "def poisson_analytic(s, lambd):\n",
    "    probs = [lambd ** k * np.exp(-lambd) / math.factorial(k) for k in range(0, int(lambd * 10))]\n",
    "    probs = np.array(probs) / np.sum(probs)\n",
    "    res = np.random.choice(np.arange(0, int(lambd * 10)), size=s, p=probs)\n",
    "    return res, probs, np.max(res)\n",
    "\n",
    "samples, probs, maxt = poisson_analytic(s, l)\n",
    "plt.figure(figsize=[12, 5])\n",
    "bar = plt.bar(np.arange(maxt + 1), probs[:maxt + 1])\n",
    "plt.bar_label(bar, np.bincount(samples))\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Discrete probability (P(x = k))\")\n",
    "plt.title(\"Poisson distribution, %d samples with λ = %.2f\" % (s, l))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_empiric(s, mu, sigma):\n",
    "    r2 = exponential_empiric(s, 1/2)\n",
    "    phi = np.random.uniform(0, 2 * np.pi, size=s)\n",
    "    return mu + np.concatenate((np.sqrt(r2) * np.sin(phi), np.sqrt(r2) * np.cos(phi))) * sigma\n",
    "\n",
    "s, mu, sigma, bins = 1_000_000, -3.5, 2.5, 750\n",
    "xrange = np.linspace(-5 * sigma, 5 * sigma, bins)\n",
    "samples = np.bincount(np.digitize(normal_empiric(s, mu, sigma), xrange), minlength=bins)[:bins]\n",
    "plt.figure(figsize=[12, 5])\n",
    "# Max at x = μ\n",
    "plt.stem(xrange, samples * (1/(sigma * np.sqrt(2 * np.pi))) \\\n",
    "    / samples[np.argsort(samples)[-5]], markerfmt=\" \")\n",
    "# Closed form of normal distr e^(-1/2*((x-μ)/σ)^2)/(sqrt(2π)σ)\n",
    "plt.plot(xrange, 1/(sigma * np.sqrt(2 * np.pi)) * np.exp(-1/2 * ((xrange - mu) / sigma) ** 2), 'r')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Value of pdf (f(x))\")\n",
    "plt.title(\"Normal distribution, %d samples, μ = %.2f and σ = %.2f\" % (s, mu, sigma))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_empiric(s, k):\n",
    "    return np.sum(normal_empiric((s, k), 0, 1) ** 2, axis=-1)\n",
    "\n",
    "s, k, bins = 2_500_000, 6, 1250\n",
    "xrange = np.linspace(0, 2 * k, bins)\n",
    "samples = np.bincount(np.digitize(chi_squared_empiric(s, k), xrange), minlength=bins)[:bins]\n",
    "plt.figure(figsize=[12, 5])\n",
    "# Max at x = k - 2\n",
    "plt.stem(xrange, samples * (k-2) ** (k/2 - 1) * np.exp((2-k)/2) / (2 ** (k/2) * sp.special.gamma(k/2)) \\\n",
    "    / samples[np.argsort(samples)[-5]], markerfmt=\" \")\n",
    "# Closed form of chi squared distribution => x^(k/2 - 1)e^(-x/2)/(2^(k/2)Г(k/2))\n",
    "plt.plot(xrange, xrange ** (k/2 - 1) * np.exp(-xrange/2) / (2 ** (k/2) * sp.special.gamma(k/2)), 'r')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Value of pdf (f(x))\")\n",
    "plt.title(\"Chi squared distribution, %d samples, and %d degrees of freedom\" % (s, k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LLN and CLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, s = 10, 5, 25_000\n",
    "xs = normal_empiric(s, a, b)\n",
    "\n",
    "ys = np.cumsum(xs) / np.arange(1, len(xs) + 1)\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.title(\"Plot of S(n)/n over %d samples\" % s)\n",
    "plt.plot(np.arange(1, len(xs) + 1), ys, label='Observed value')\n",
    "plt.plot(np.arange(1, len(xs) + 1), [a] * len(xs), 'r', label='Theoretical expected value')\n",
    "plt.xlabel(\"samples\")\n",
    "plt.ylabel('S(n)/n')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final observation: %d\" % ys[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z(s, n, mu, sigma):\n",
    "    return np.sqrt(n) * (np.mean(normal_empiric((s, n), mu, sigma), axis=-1) - mu)# / sigma\n",
    "\n",
    "a, b, s, n, bins = 7.5, 2.5, 250_000, 250, 500\n",
    "xrange = np.linspace(-5 * b, 5 * b, bins)\n",
    "samples = np.bincount(np.digitize(Z(s, n, a, b), xrange), minlength=bins)[:bins]\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.stem(xrange, samples * (1/(b * np.sqrt(2 * np.pi))) / samples[np.argsort(samples)[-5]], markerfmt=\" \")\n",
    "plt.plot(xrange, 1/(b * np.sqrt(2 * np.pi)) * np.exp(-1/2 * (xrange / b) ** 2), 'r', label='normal_distribution_N(0, b^2)')\n",
    "plt.plot(xrange, 1/(b * np.sqrt(2 * np.pi)) * np.exp(-1/2 * ((xrange - a) / b) ** 2), 'g', label='original_distribution_N(a, b^2)')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Value of pdf (f(x))\")\n",
    "plt.legend()\n",
    "plt.title(\"Plot of resulting distribution, estimated with 10000 iid normal variables and 25000 samples, each with μ = %.2f and σ = %.2f\" % (a, b))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z2(s, n, lambd):\n",
    "    return np.sqrt(n) * (np.mean(exponential_empiric((s, n), lambd), axis=-1) - 1/lambd)\n",
    "\n",
    "lambd, s, n, bins = 2, 250_000, 10_000, 500\n",
    "xrange = np.linspace(-5 * b, 5 * b, bins)\n",
    "samples = np.bincount(np.digitize(Z2(s, n, lambd), xrange), minlength=bins)[:bins]\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.stem(xrange, samples * (1/(b * np.sqrt(2 * np.pi))) / samples[np.argsort(samples)[-5]], markerfmt=\" \")\n",
    "plt.plot(xrange, 1/(b * np.sqrt(2 * np.pi)) * np.exp(-1/2 * (xrange / b) ** 2), 'r', label='standardized_sample_mean')\n",
    "plt.plot(xrange, 1/(b * np.sqrt(2 * np.pi)) * np.exp(-1/2 * ((xrange - a) / b) ** 2), 'g', label='original distribution')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Value of pdf (f(x))\")\n",
    "plt.legend()\n",
    "plt.title(\"Plot of standardized sample mean, %d samples, estimated with %d iid normal variables, each with μ = %.2f and σ = %.2f\" % (s, n, a, b))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def I(x):\n",
    "    res = np.exp(-(np.sum(x, axis=1) + 1 / (2 ** (2 * x.shape[1]) * np.prod(x, axis=1)))) \\\n",
    "        * np.prod(x ** (-np.arange(1, x.shape[1] + 1) / (x.shape[1] + 1)), axis=1)\n",
    "    res = np.nan_to_num(res, nan=0)\n",
    "    return res\n",
    "\n",
    "def monte_carlo_integrate(s, d, step):\n",
    "    avg, c, total, lambd = [0], 1, 0, 1\n",
    "    for _ in range(step):\n",
    "        xs = exponential_empiric((s, d), lambd)\n",
    "        total = np.sum(I(xs) / np.prod(lambd * np.exp(-xs * lambd), axis=1)) / s\n",
    "        avg.append(avg[-1] + (total - avg[-1]) / c)\n",
    "        c += 1\n",
    "    return avg[1:]\n",
    "\n",
    "samples_per_step, d, steps = 100_000, 10, 100_000\n",
    "results = monte_carlo_integrate(samples_per_step, d, steps)\n",
    "plt.plot(np.arange(0, steps), results)\n",
    "plt.plot(np.arange(0, steps), [results[-1]] * steps, 'r')\n",
    "plt.title(\"Numerical approximation of I(%d), with %d steps, each %d samples\\nMonte Carlo Integration\" % (d, steps, samples_per_step))\n",
    "plt.xlabel(\"Step count\")\n",
    "plt.ylabel(\"Numerical approximation\")\n",
    "plt.show()\n",
    "print(\"Final approximation of integral on %d dimensions, with %d steps, each %d samples: %.10f\" % (d, steps, samples_per_step, results[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riemann_sum(xs, w, l, rsum=0):\n",
    "    ys = I(xs)\n",
    "    yys = []\n",
    "    for i, e in enumerate(ys[1:]):\n",
    "        yys.append([ys[i], e])\n",
    "    yys = np.array(yys)\n",
    "    rsum += np.sum(np.max(yys, axis=1)) * w\n",
    "    return rsum / l\n",
    "\n",
    "def cartesian(arrays, out=None):\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "    m = int(n / arrays[0].size)\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m, 1:])\n",
    "        for j in range(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m, 1:] = out[0:m, 1:]\n",
    "    return out\n",
    "\n",
    "domain, d = np.linspace(0, 5, 10), 1\n",
    "print(\"Final approximation of integral on %d dimensions, with %d samples: %.10f\" % \\\n",
    "    (d, len(domain), riemann_sum(cartesian(np.tile(domain, (d, 1))), domain[-1] - domain[0], len(domain))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Unit simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform dirichlet -> α = [1](d), turns to a special case where Xs are exponentially distributed\n",
    "def dirichlet_uniform(s, d):\n",
    "    xs = exponential_empiric((s, d), 1)\n",
    "    return xs / np.sum(xs, axis=1, keepdims=True)\n",
    "\n",
    "s, d, subs = 30_000, 3, [25, 10, 5, 1]\n",
    "results = dirichlet_uniform(s, d)\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0, wspace=0)\n",
    "(ax1, ax2), (ax3, ax4) = gs.subplots(sharex=\"col\", sharey='row')\n",
    "fig.suptitle(\"Flat Dirichlet distribution, (α_n = 1 for all dimensions, or uniform), only first 2 of %d dimensions shown\" % d)\n",
    "for ax, sub in zip([ax1, ax2, ax3, ax4], subs):\n",
    "    ax.scatter(results[:max(1, s // sub), 0], results[:max(1, s // sub), 1], s=.1)\n",
    "    ax.set_title(\"%d samples\" % (max(1, s // sub)), y=1.0, pad=-15)\n",
    "    ax.label_outer()\n",
    "ax.set_xlabel(\"X_1\")\n",
    "ax.set_ylabel(\"X_2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_dirichlet(s, d, mu, sigma):\n",
    "    xs, curr = [], []\n",
    "    while len(xs) < s:\n",
    "        curr = normal_empiric((s, d), mu, sigma)\n",
    "        curr = curr[np.setdiff1d(np.arange(0, s), np.union1d( \\\n",
    "            np.nonzero((curr < 0).sum(axis = 1))[0], \\\n",
    "            np.nonzero((curr > 1).sum(axis = 1))[0]))]\n",
    "        xs.extend(curr)\n",
    "    xs = np.array(xs[:s])\n",
    "    return xs / np.sum(xs, axis=1, keepdims=True)\n",
    "\n",
    "s, d, mu, sigma, subs = 30_000, 3, 1 / d, 0.4, [25, 10, 5, 1]\n",
    "results = centered_dirichlet(s, d, mu, sigma)\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0, wspace=0)\n",
    "(ax1, ax2), (ax3, ax4) = gs.subplots(sharex=\"col\", sharey='row')\n",
    "fig.suptitle(\"Dirichlet distribution, normally distributed samples, μ = %.2f and σ = %.2f, only first 2 of %d dimensions shown\" % (mu, sigma, d))\n",
    "for ax, sub in zip([ax1, ax2, ax3, ax4], subs):\n",
    "    ax.scatter(results[:max(1, s // sub), 0], results[:max(1, s // sub), 1], s=.1)\n",
    "    ax.set_title(\"%d samples\" % (max(1, s // sub)), y=1.0, pad=-15)\n",
    "    ax.label_outer()\n",
    "ax.set_xlabel(\"X_1\")\n",
    "ax.set_ylabel(\"X_2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_dirichlet(alpha, s):\n",
    "    return sp.stats.dirichlet.rvs(alpha, s)\n",
    "\n",
    "s, d, subs, alpha = 30_000, 3, [25, 10, 5, 1], [2, 2, 2]\n",
    "\n",
    "results = general_dirichlet(alpha, s)\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0, wspace=0)\n",
    "(ax1, ax2), (ax3, ax4) = gs.subplots(sharex=\"col\", sharey='row')\n",
    "fig.suptitle(\"Dirichlet distribution, α = %s, only first 2 of %d dimensions shown\" % (str(alpha), d))\n",
    "for ax, sub in zip([ax1, ax2, ax3, ax4], subs):\n",
    "    ax.scatter(results[:max(1, s // sub), 0], results[:max(1, s // sub), 1], s=.1)\n",
    "    ax.set_title(\"%d samples\" % (max(1, s // sub)), y=1.0, pad=-15)\n",
    "    ax.label_outer()\n",
    "ax.set_xlabel(\"X_1\")\n",
    "ax.set_ylabel(\"X_2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbformat_minor": 2,
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
